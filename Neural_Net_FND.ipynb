{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "SEZlOM84EeEA",
   "metadata": {
    "id": "SEZlOM84EeEA"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/gerakys/PyhtonProject_DMTA/blob/main/Neural_Net_FND.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lQ7LImVTDHel",
   "metadata": {
    "id": "lQ7LImVTDHel"
   },
   "source": [
    "# Fake News Detection using Neural Networks\n",
    "---\n",
    "In this notebook, our mission is to construct a robust neural network for discerning the authenticity of news articles. The approach will be as follows:\n",
    "\n",
    "* Data Exploration and Cleaning\n",
    "* Data Selection and Encoding\n",
    "* Text Preprocessing\n",
    "* Neural Network Architecture\n",
    "* Model Training and Evalutation\n",
    "* Real-time Prediction\n",
    "\n",
    "An example of a real and fake news are shown below.\n",
    "\n",
    "<img src='notebook_ims/real_fake_example.png' width=50% height=80%/>\n",
    "\n",
    "Our dataset comprises a collection of news articles labeled as either real or fake. We meticulously explore and preprocess this data to ensure our neural network receives high-quality inputs for training and evaluation.\n",
    "\n",
    "Let's Begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "521864a9",
   "metadata": {
    "id": "521864a9"
   },
   "outputs": [],
   "source": [
    "# We import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccf019e6-894e-434c-978c-bc1299413199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382b485",
   "metadata": {},
   "source": [
    "## Load in and Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cf2a31d",
   "metadata": {
    "id": "6cf2a31d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"data/fake_or_real_news.csv\")\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dd2456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check for any missing values\n",
    "data.isnull().sum() # there are not\n",
    "# We see if our dataset is balanced\n",
    "data['label'].value_counts() # it is!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d40a20",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The initial step in constructing our neural network is preparing the data for effective input. As we intend to incorporate a word-embedding layer, the following steps are undertaken:\n",
    "\n",
    "1. **Encoding Words and Labels:**\n",
    "   - Encode each word in the news articles as an integer.\n",
    "   - Encode news labels, representing real as 1 and false as 0.\n",
    "\n",
    "2. **Tokenization:**\n",
    "   - Utilize the `Tokenizer` class to create a vocabulary of unique words.\n",
    "   - Fit the tokenizer on the dataset to associate each word with a unique integer.\n",
    "\n",
    "3. **Text to Sequences:**\n",
    "   - Transform the textual data into sequences of integers using the fitted tokenizer.\n",
    "   - This step helps in numerical representation of the news headlines.\n",
    "\n",
    "4. **Padding Sequences:**\n",
    "   - Apply padding to the sequences to ensure uniform length across all data points.\n",
    "   - Pad sequences with zeros to match the desired length, enhancing model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64623ac6",
   "metadata": {
    "id": "64623ac6"
   },
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "x = np.array(data[\"title\"])\n",
    "y = np.array(data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "883fdbe7",
   "metadata": {
    "id": "883fdbe7"
   },
   "outputs": [],
   "source": [
    "# Convert labels to numerical format\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c859c773",
   "metadata": {
    "id": "c859c773"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = tokenizer.texts_to_sequences(x)\n",
    "x = pad_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3dc7150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 1\n",
      "to: 2\n",
      "in: 3\n",
      "of: 4\n",
      "trump: 5\n",
      "for: 6\n",
      "on: 7\n",
      "a: 8\n",
      "and: 9\n",
      "is: 10\n",
      "clinton: 11\n",
      "hillary: 12\n",
      "with: 13\n",
      "obama: 14\n",
      "new: 15\n",
      "by: 16\n",
      "as: 17\n",
      "donald: 18\n",
      "from: 19\n",
      "at: 20\n"
     ]
    }
   ],
   "source": [
    "# we take a look at our vocabulary\n",
    "indice_parole = tokenizer.word_index\n",
    "for word, index in list(indice_parole.items())[:20]:\n",
    "    print(f\"{word}: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4758741",
   "metadata": {},
   "source": [
    "## Let's Build our Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5adcb3",
   "metadata": {},
   "source": [
    "First step will be splitting the data into training and testing sets.\n",
    "This is a crucial step in preparing our dataset for training and evaluating the model.\n",
    "Using the train_test_split function from sklearn, we divide our data into training and testing sets.\n",
    "We allocate 80% of the data for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "412acb1c",
   "metadata": {
    "id": "412acb1c"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5c80a",
   "metadata": {},
   "source": [
    "The layers are as follows:\n",
    "* An embedding layer that converts our word tokens (integers) into embeddings of a specific size.\n",
    "* A dropout layer to prevent overfitting by deactivating 20% of the previous embeddings.\n",
    "* An LSTM layer defined by a hidden_state size and number of layers\n",
    "* A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
    "* A sigmoid activation layer which turns all outputs into a value 0-1; return only the last sigmoid output as the output of this network.\n",
    "* Compile the model with binary crossentropy loss, adam optimizer, and accuracy metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "284d10b2",
   "metadata": {
    "id": "284d10b2"
   },
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=x.shape[1])) \n",
    "model.add(SpatialDropout1D(0.2)) \n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "336560dd-67de-414b-8c60-e0aa99d8ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ade537e8",
   "metadata": {
    "id": "ade537e8",
    "outputId": "ab1531cf-81b8-4a96-b2b6-6a44ff0a831a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "127/127 [==============================] - 8s 40ms/step - loss: 0.5672 - accuracy: 0.6929 - precision_3: 0.7238 - recall_3: 0.6170 - val_loss: 0.4400 - val_accuracy: 0.7850 - val_precision_3: 0.7867 - val_recall_3: 0.7958\n",
      "Epoch 2/10\n",
      "127/127 [==============================] - 5s 36ms/step - loss: 0.2852 - accuracy: 0.8883 - precision_3: 0.8873 - recall_3: 0.8877 - val_loss: 0.4419 - val_accuracy: 0.7949 - val_precision_3: 0.8008 - val_recall_3: 0.7977\n",
      "Epoch 3/10\n",
      "127/127 [==============================] - 4s 33ms/step - loss: 0.1551 - accuracy: 0.9410 - precision_3: 0.9409 - recall_3: 0.9404 - val_loss: 0.5364 - val_accuracy: 0.7939 - val_precision_3: 0.7788 - val_recall_3: 0.8343\n",
      "Epoch 4/10\n",
      "127/127 [==============================] - 4s 33ms/step - loss: 0.1134 - accuracy: 0.9618 - precision_3: 0.9563 - recall_3: 0.9672 - val_loss: 0.5824 - val_accuracy: 0.7850 - val_precision_3: 0.7692 - val_recall_3: 0.8285\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16311d8d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(xtrain, ytrain, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240333d",
   "metadata": {},
   "source": [
    "# Model Evaluation on Test Set\n",
    "\n",
    "Here, we assess the performance of our trained model on the test set. The evaluation includes metrics such as loss, accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e52f99a9",
   "metadata": {
    "id": "e52f99a9",
    "outputId": "dd1562d4-9156-4ed1-b0df-1581e9871424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6415 - accuracy: 0.7782 - precision_3: 0.7572 - recall_3: 0.8247\n",
      "Model Accuracy: 0.78\n",
      "Model Loss: 0.641485869884491\n",
      "Precision: 0.76\n",
      "Recall: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy, precision, recall = model.evaluate(xtest, ytest)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Model Loss: {loss}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58293933",
   "metadata": {},
   "source": [
    "The output shows the accuracy, loss, precision and recall achieved by the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50de1b",
   "metadata": {},
   "source": [
    "# Real-time Prediction\n",
    "We also demonstrate the real-time prediction capability of the model using a sample news headline entered by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1b94dc6",
   "metadata": {
    "id": "d1b94dc6",
    "outputId": "25a2967d-20c9-4403-d39a-cc68cb8e098b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type News title here:  COVID-19 vaccinations contain microchips for global tracking. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step\n",
      "Predicted Label: Fake (Probability: 0.55)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on a sample news headline\n",
    "news_headline = input(\"Type News title here: \")\n",
    "headline_seq = tokenizer.texts_to_sequences(news_headline)\n",
    "headline_padded = pad_sequences(headline_seq, maxlen=x.shape[1])\n",
    "result = model.predict(headline_padded)[0][0]\n",
    "predicted_label = \"Real\" if result < 0.5 else \"Fake\"\n",
    "print(f\"Predicted Label: {predicted_label} (Probability: {result:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e65cc94",
   "metadata": {
    "id": "0fcfee1a"
   },
   "source": [
    "In this example, the user inputs a news headline, and the model predicts whether it is real or fake, along with the associated probability."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
